{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP03 - Classificação Portas Lógicas\n",
    "\n",
    "Bem vindo!\n",
    "Neste TP você implementará um algoritmo de classificação.\n",
    "\n",
    "**Instruções:**\n",
    "- Use a versão Python 3.\n",
    "- Evite sempre usar usar laços `for` e `while`, fazer contas no formato vetorial é sempre mais rápido.\n",
    "- Não apague os comentários existentes, mas é claro que você pode adicionar outros comentários!\n",
    "\n",
    "**Objetivos**\n",
    "- Implementar perceptron de camada única para classificar \"portas lógicas\"\n",
    "- Aplicar o algoritmo de aprendizado do perceptron\n",
    "- Verificar na prática convergência do perceptron para problemas linearmente separáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Jupyter notebook\n",
    "\n",
    "O Jupyter Notebook é um ambiente interativo de programação em uma página web. Nesse notebook você colocará o código entre os comentários `### SEU CÓDIGO COMEÇA AQUI ###` e `### FIM DO CÓDIGO ###`. Após escrever o código, você pode executar a célula com `Shift+Enter` ou no botão \"Run\" (com símbolo de \"play\") na barra de comandos acima.\n",
    "\n",
    "Em alguns trechos será especificado \"(≈ X linhas de código)\" nos comentários para que você tenha uma ideia sobre o tamanho do código a ser desenvolvido naquele trecho. Lembrando que é só uma estimativa, o seu código pode ficar maior ou menor do que o especificado.\n",
    "\n",
    "**Alguns atalhos úteis *no código*:**\n",
    "- `Ctrl+Enter`: executa a célula e mantém o cursor na mesma célula\n",
    "- `Shift+Enter`: executa a célula e move o cursor para a próxima célula\n",
    "- `Ctrl+/`: comenta a linha de código\n",
    "- `Shift+Tab`: quando o cursor estiver em uma função, mostra um HELP da função\n",
    "\n",
    "**Alguns atalhos úteis *na célula*:**\n",
    "- Cria nova célula `a`: acima, `b`: abaixo da céula selecionada\n",
    "- `d` (2x): deleta célula selecionada\n",
    "- `m`: define célula como texto (Markdown)\n",
    "- `y`: define célula como código (Python)\n",
    "- `l`: mostra numeração das linhas na célula de código\n",
    "- `c`: copiar, `v`: colar, `x`: recortar célula selecionada\n",
    "- `ctrl+shift+p`: mostra busca para todos comandos de célula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escreva o seu RA na variável abaixo\n",
    "Atribua o número do seu RA, sem os zeros à esquerda, na variável `RA` abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SEU CÓDIGO COMEÇA AQUI ### (≈ 1 linha de código)\n",
    "RA = None\n",
    "### FIM DO CÓDIGO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados linearmente separáveis\n",
    "O código abaixo gera um conjunto de dados com 100 amostras, $m=100$, de um problema de classificação. Primeiramente, você ajustará, manualmente, uma rede neural que consiga classificar os dados abaixo.\n",
    "\n",
    "<mark>**Faça:** </mark>\n",
    "1. Rode o código abaixo e observe que as classes são linearmente separáveis na maioria das realizações (cada vez que o código é rodado, são sorteados novos dados)\n",
    "1. O modelo classificador será o Perceptron de camada única, dado por: $\\hat{y}^{(i)}= \\textrm{sign}\\left(w_1 x_1^{(i)} + w_2 x_2^{(i)} + b\\right)$\n",
    "1. Ajuste, manualmente, os valores dos pesos $w_1$, $w_2$ e $b$ de modo que o modelo consiga classificar os dados corretamente\n",
    "1. Faça, no mesmo gráfico mostrado, uma reta representando o limiar de decisão do Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# dados de treinamento\n",
    "m = 100\n",
    "np.random.seed()\n",
    "x1_train = np.random.randint(2, size=m)\n",
    "x2_train = np.random.randint(2, size=m)\n",
    "np.random.seed(RA*283)\n",
    "oraculo = (np.logical_and, np.logical_or)[np.random.randint(0,2)]\n",
    "y_train = oraculo(x1_train, x2_train).astype(int)*2-1\n",
    "x1_train = x1_train*2-1 + np.random.normal(0, .2, m) # adicionando ruído\n",
    "x2_train = x2_train*2-1 + np.random.normal(0, .2, m) # adicionando ruído\n",
    "\n",
    "plt.figure(figsize=(4,3), dpi=100)\n",
    "plt.plot(x1_train[y_train<0], x2_train[y_train<0], 'o', c='blue')\n",
    "plt.plot(x1_train[y_train>0], x2_train[y_train>0], 's', c='red')\n",
    "\n",
    "\n",
    "### SEU CÓDIGO COMEÇA AQUI ### (≈ 3 linhas de código)\n",
    "\n",
    "# parametros ajustados MANUALMENTE\n",
    "w1 = None\n",
    "w2 = None\n",
    "b = None\n",
    "\n",
    "### FIM DO CÓDIGO ###\n",
    "\n",
    "# Calcula reta (limiar de decisão)\n",
    "x1_plot = np.linspace(-2.0, 2.8, 50)\n",
    "x2_plot = (-w1/w2)*x1_plot -b/w2\n",
    "\n",
    "plt.plot(x1_plot, x2_plot, 'k--')\n",
    "plt.legend(('$y=-1$','$y=+1$'))\n",
    "plt.xlim((-2, 2.8))\n",
    "plt.ylim((-2, 2.8))\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada**\n",
    "\n",
    "<img src=\"files/TP03_classificador.png\">\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron de camada única\n",
    "\n",
    "<mark>**Faça:**</mark>\n",
    "Crie agora a classe `perceptron()` que implementará o modelo do Perceptron de camada única, cuja equação é dada por:\n",
    "\n",
    "$\\hat{y}^{(i)}= \\textrm{sign}\\left(w_1 x_1^{(i)} + w_2 x_2^{(i)} + b\\right)$\n",
    "\n",
    "\n",
    "Lembre-se que $\\hat{y}\\in\\{-1,1\\}$. Assim, a saída da função só pode fornecer os valores $-1$ ou $+1$.\n",
    "\n",
    "A classe deve possuir os seguintes atributos obrigatórios:\n",
    "  + $w_1$: primeiro valor de peso, escalar, no formato `type(w1)=float`\n",
    "  + $w_2$: segundo valor de peso, escalar, no formato `type(w2)=float`\n",
    "  + $b$: valor do parâmetro bias, escalar, no formato `type(b)=float`\n",
    "\n",
    "Semelhante ao TP anterior, implemente a função `setWeights`, que recebe como parâmetros novos valores de peso para serem ajustados.\n",
    "\n",
    "Semelhante ao TP anterior, implemente a função `forward`, que calcula a saída $\\hat{y}$ estimada para valores de entrada passados como parâmetros.\n",
    "\n",
    "Ao final, teste a classe e as funções usando os parâmetros $w_1$, $w_2$ e $b$ ajustados manualmente na etapa anterior para todos os $m=100$ dados gerados. Gere um gráfico semelhante ao do exercício anterior, mostrando que o modelo funcionou corretamente. Ao final, calcule e mostre (comando `print`) o erro quadrático médio (*mean squared error*, MSE) do resultado. Espera-se `MSE≈0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3), dpi=100)\n",
    "\n",
    "### SEU CÓDIGO COMEÇA AQUI ###\n",
    "class perceptron():\n",
    "    def __init__(self, ...):\n",
    "        ...\n",
    "    \n",
    "    def setWeights(self, novo_w1, novo_w2, novo_b):\n",
    "        ...\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        return ...\n",
    "\n",
    "# instancia a classe\n",
    "...\n",
    "\n",
    "# ajusta pesos\n",
    "...\n",
    "\n",
    "# calcula saídas\n",
    "yh = None\n",
    "\n",
    "### FIM DO CÓDIGO ###\n",
    "\n",
    "plt.plot(x1_train[y_train<0], x2_train[y_train<0], 'o', c='blue')\n",
    "plt.plot(x1_train[y_train>0], x2_train[y_train>0], 's', c='red')\n",
    "\n",
    "plt.plot(x1_train[yh>0],x2_train[yh>0],'rx', ms=10, label=\"$\\hat{y}=+1$\")\n",
    "plt.plot(x1_train[yh<0],x2_train[yh<0],'bx', ms=10, label=\"$\\hat{y}=-1$\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim((-2, 2.8))\n",
    "plt.ylim((-2, 2.8))\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada**\n",
    "- Gráfico no plano de entradas $(x_1, x_2)$, mostrando que o modelo classificou corretamente. Você pode usar símbolos diferentes para representar as classes \"+1\" e \"-1\". Coloque legenda no gráfico!\n",
    "- Cálculo do MSE com saída `MSE = 0.0`.\n",
    "___\n",
    "\n",
    "## Treinamento do Perceptron de camada única\n",
    "\n",
    "Para ajustar os parâmetros $w1$, $w2$ e $b$ de forma automática, baseado nos dados de treinamento, a seguinte regra de aprendizado pode ser utilizada:\n",
    "\n",
    "$w_i^{(k)} = w_i^{(k-1)} + \\Delta w_i^{(k-1)},\\,\\,\\,\\,\\,\\,\\,$    (1)\n",
    "\n",
    "$b^{(k)} = b^{(k-1)} + \\Delta b^{(k-1)},\\,\\,\\,\\,\\,\\,\\,$    (2)\n",
    "\n",
    "em que $w_i^{(k)}$ representa o $i$-ésimo peso da $k$-ésima iteração do algoritmo de aprendizado, e tem-se:\n",
    "\n",
    "$\\Delta w_i^{(k)}=\\eta [y-\\hat{y}]x_i^{(k)},\\,\\,\\,\\,\\,\\,\\,$    (3)\n",
    "\n",
    "$\\Delta b^{(k)}=\\eta [y-\\hat{y}],\\,\\,\\,\\,\\,\\,\\,$    (4)\n",
    "\n",
    "sendo $\\eta$ o hiperparâmetro que controla a *taxa de aprendizado* do algoritmo.\n",
    "\n",
    "<mark>**Faça:**</mark>Crie uma função `train(modelo, x1, x2, y, eta, epocas)` que implementa o algoritmo de aprendizado do Perceptron descrito acima.\n",
    "- Entradas \n",
    "  + `modelo`: modelo Perceptron (da classe criada anteriormente)\n",
    "  + `x1`: vetor com dados de treinamento referente à entrada 1 do modelo\n",
    "  + `x2`: vetor com dados de treinamento referente à entrada 2 do modelo\n",
    "  + `y`: vetor com dados de treinamento referente à saída do modelo\n",
    "  + `eta`: variável que representa a *taxa de aprendizado*\n",
    "  + `epocas`: *épocas de treinamento*, variável que define o número de vezes que o algoritmo de aprendizado vai passar por cada amostra\n",
    "- Saída\n",
    "  + `modelo`: modelo Perceptron treinado\n",
    "\n",
    "O algoritmo de aprendizado terá as seguintes características:\n",
    "1. Devem ser usados os mesmos dados de treinamento da primeira parte dessa atividade\n",
    "1. As funções desenvolvidas anteriormente (`forward` e `setWeights`) devem ser utilizadas\n",
    "1. A classe deve iniciar os valores dos pesos `w1`, `w2` e `b` de forma aleatória antes do treinamento (garanta que os pesos tenham valores atribuidos ao instanciar a classe)\n",
    "1. O aprendizado deve ocorrer dentro de um laço `for` que passa por todos os $m$ dados de treinamento por pelo menos uma vez. O número de vezes que o treinamento vai passar por cada dado é definido no parâmetro `epocas`. Exemplo: se numa situação temos $m=10$ e `epocas=3`, então o laço `for` terá 30 iterações ao todo.\n",
    "1. Dentro do laço, seu código deve fazer o seguinte:\n",
    "   1. Passo de propagação (*forward step*): calcule a saída da rede $\\hat{y}^{(i)}$ para as respectivas entradas $x_1^{(i)}$ e $x_2^{(i)}$\n",
    "   1. Para o parâmetro $w_1$, calcule $\\Delta w_1^{(i-1)}$, conforme equação (3) acima\n",
    "   1. Para o parâmetro $w_2$, calcule $\\Delta w_2^{(i-1)}$, conforme equação (3) acima\n",
    "   1. Para o parâmetro $b$, calcule $\\Delta b^{(i-1)}$, conforme equação (4) acima\n",
    "   1. Calcule o novo valor $w_1^{(i)}$, baseado em $w_1^{(i-1)}$ e $\\Delta w_1^{(i-1)}$, conforme equação (2) acima\n",
    "   1. Calcule o novo valor $w_2^{(i)}$, baseado em $w_2^{(i-1)}$ e $\\Delta w_2^{(i-1)}$, conforme equação (2) acima\n",
    "   1. Calcule o novo valor $b^{(i)}$, baseado em $b^{(i-1)}$ e $\\Delta b^{(i-1)}$, conforme equação (1) acima\n",
    "   1. faça os passos anteriores para a próxima amostra\n",
    "1. O laço descrito anteriormente deve percorrer os dados de treinamento de forma aleatória! Os dados não podem sers percorridos na ordem de apresentação dos dados. Para fazer isso, use a função `np.random.permutation`\n",
    "\n",
    "Após implementar a função de treinamento, use-a para calcular `yh`. Os resultados serão apresentados no plano $(x_1, x_2)$ para os dados de treinamento. Calcule também o MSE na variável `MSE_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SEU CÓDIGO COMEÇA AQUI ###\n",
    "    \n",
    "def train(modelo, x1, x2, y, eta, epocas):\n",
    "    ...\n",
    "    \n",
    "    return modelo\n",
    "\n",
    "# pesos iniciais (antes do treinamento)\n",
    "w1_0 = None\n",
    "w2_0 = None\n",
    "b_0 = None\n",
    "\n",
    "# inicia modelo\n",
    "modelo = None\n",
    "\n",
    "# treinamento\n",
    "...\n",
    "\n",
    "# verifica desempenho nos dados de treinamento\n",
    "yh = None\n",
    "MSE_train = None\n",
    "\n",
    "### FIM DO CÓDIGO ###\n",
    "\n",
    "print('MSE (treinamento): %.3f'%MSE_train)\n",
    "\n",
    "plt.plot(x1_train[y_train<0], x2_train[y_train<0], 'o', c='blue')\n",
    "plt.plot(x1_train[y_train>0], x2_train[y_train>0], 's', c='red')\n",
    "\n",
    "plt.plot(x1_train[yh>0],x2_train[yh>0],'rx', ms=10, label=\"$\\hat{y}=+1$\")\n",
    "plt.plot(x1_train[yh<0],x2_train[yh<0],'bx', ms=10, label=\"$\\hat{y}=-1$\")\n",
    "\n",
    "x1_plot = np.linspace(-2.0, 2.8, 50)\n",
    "x2_plot = (-w1_0/w2_0)*x1_plot - b_0/w2_0\n",
    "x2_plot_treinado = (-modelo.w1/modelo.w2)*x1_plot - modelo.b/modelo.w2\n",
    "\n",
    "plt.plot(x1_plot, x2_plot, ':k');\n",
    "plt.plot(x1_plot, x2_plot_treinado, '-k');\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim((-2, 2.8))\n",
    "plt.ylim((-2, 2.8))\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada**:\n",
    "- gráfico, similar ao da primeira parte desta atividade, mostrando o resultado do modelo nos dados de treinamento.\n",
    "- MSE nos dados de treinamento\n",
    "___\n",
    "Usando o modelo já treinado, calcule os resultados para os dados de teste em `yh_teste`, que estão nas variáveis `x1_test`, `x2_test` e `y_test`. No gráfico, mostre dois limiares de separação: aquele obtido com os pesos iniciais (**antes** do treinamento) e o limiar de serparação obtido pelo o modelo treinado (**após** o treinamento). Calcule também o MSE nos dados de validação e apresente seu valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# dados de teste\n",
    "m_test = 50\n",
    "x1_test = np.random.randint(2, size=m_test)\n",
    "x2_test = np.random.randint(2, size=m_test)\n",
    "y_test = np.logical_and(x1_test, x2_test).astype(int)*2-1\n",
    "x1_test = x1_test*2-1 + np.random.normal(0, .25, m_test) # adicionando ruído\n",
    "x2_test = x2_test*2-1 + np.random.normal(0, .25, m_test) # adicionando ruído\n",
    "\n",
    "### SEU CÓDIGO COMEÇA AQUI ###\n",
    "\n",
    "# Desempenho nos dados de teste\n",
    "yh_test = None\n",
    "MSE_test = None\n",
    "\n",
    "### FIM DO CÓDIGO ###\n",
    "\n",
    "print('MSE (teste): %.3f'%MSE_test)\n",
    "\n",
    "plt.plot(x1_test[y_test<0], x2_test[y_test<0], 'o', c='blue')\n",
    "plt.plot(x1_test[y_test>0], x2_test[y_test>0], 's', c='red')\n",
    "\n",
    "plt.plot(x1_test[yh_test>0],x2_test[yh_test>0],'rx', ms=10, label=\"$\\hat{y}=+1$\")\n",
    "plt.plot(x1_test[yh_test<0],x2_test[yh_test<0],'bx', ms=10, label=\"$\\hat{y}=-1$\")\n",
    "\n",
    "x1_plot = np.linspace(-2.0, 2.8, 50)\n",
    "x2_plot_treinado = (-modelo.w1/modelo.w2)*x1_plot - modelo.b/modelo.w2\n",
    "\n",
    "plt.plot(x1_plot, x2_plot_treinado, '-k');\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim((-2, 2.8))\n",
    "plt.ylim((-2, 2.8))\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada**:\n",
    "- gráfico, similar ao da primeira parte desta atividade, mostrando o resultado do modelo nos dados de teste.\n",
    "- MSE nos dados de teste\n",
    "___\n",
    "\n",
    "## Desafio! (opcional, você não perderá nenhum ponto se deixar de fazer essa parte)\n",
    "\n",
    "Você pode tentar um novo desafio: utilizar o algoritmo de aprendizado implementado nos dados da Iris. Esses dados podem ser obtidos no site https://archive.ics.uci.edu/ml/datasets/Iris, que contém também uma descrição mais completa do problema.\n",
    "\n",
    "Implemente o algoritmo de aprendizado fazendo os ajustes necessários. Ao final, mostre o resultado do algoritmo de aprendizado para os **dados de validação**. Não se esqueça de segregar o conjunto de dados em: treinamento (\\~80%) e validação (\\~20%). Mostre o percentual de acerto nesses dados.\n",
    "\n",
    "Bom trabalho!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SEU CÓDIGO COMEÇA AQUI ###\n",
    "\n",
    "### FIM DO CÓDIGO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada**:\n",
    "índice de acerto nos dados de validação e demais gráficos que achar convenientes.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "228px",
    "width": "370px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
